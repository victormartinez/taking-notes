# Kubernetes: Objetos
O Kubernetes utiliza o conceito de objeto para designar um recurso do cluster. Esse objeto pode ser a representa√ß√£o de uma aplica√ß√£o, uma configura√ß√£o de rede, Load Balancer, etc. O objeto √© descrito por meio de arquivos `yaml` que especificam o estado final desejado e uma vez executado o K8s vai trabalhar para garantir o estado desejado.

## POD
Corresponde a uma aplica√ß√£o do cluster que pode ser composta de um ou mais containers. √â o menor objeto que voc√™ pode criar no cluster.

> Por que deploys n√£o gerenciam diretamente containers de forma individual? √Äs vezes um grupo de containers precisam ser escalonados juntos, executando no mesmo node e comunicando localmente, talvez compartilhando *storage* ou cache (por exemplo).


## Service
Pods s√£o vol√°teis e o K8s n√£o garante que eles estar√£o vivos para sempre. Dessa forma, o Service representa um grupo l√≥gico de Pods e funciona como *gateway* de forma a permitir que outros pods mandem requests para o servi√ßo sem ter que conhecer a rede dos Pods.

Um grupo de Pods apontado por um service √© comumente determinado por um `label selector` (isso torna f√°cil apontar o servi√ßo para um grupo de Pods diferentes durante um upgrade ou blue/green deploy).

## Volume
Storage. Aplic√°vel a todo o pod e √© montado em todos os containers do pod. Removido apenas quando o pod √© destru√≠do.

## Namespace
Cluster virtual. *Isolation of concerns*. **Recursos de um namespace n√£o podem acessar recursos de outro namespace.**

## Deployment
Objeto que descreve o estado esperado de um Pod ou ReplicaSet. Deployments s√£o criados, geralmente, atrav√©s de arquivos de Manifesto (YAML).

```
‚ö†Ô∏è Aten√ß√£o: r√©plicas gerenciadas atrav√©s de um deployment n√£o devem ser manipuladas diretamente, apenas por meio de um novo deployment.
```

## ReplicaSet (Controller)

Controlados pelo Deployment. Asseguram que o n√∫mero de pods desejado para aquele deploy est√° rodando. Deployments n√£o gerenciam Pods diretamente, esse trabalho √© do ReplicaSet. Deployments, na verdade, gerenciam ReplicaSet e controlam como as r√©plicas se comportam quando atualizadas (lan√ßando uma nova vers√£o da aplica√ß√£o, por exemplo). O Controller ReplicaSet vai dar start/stop em alguns pods para retificar a situa√ß√£o. Quando voc√™ atualiza o Deployment, um novo ReplicaSet √© criado para gerenciar os Pods. Quando a atualiza√ß√£o √© finalizada, a replicaset antiga e seus pods s√£o terminados.

OBS: A cria√ß√£o de um Deployment automaticamente cria um Replicaset.

![Rela√ß√£o entre Deployment, ReplicaSet e Pod](./imgs/deployment-replicaset-pod.png "Rela√ß√£o entre Deployment, ReplicaSet e Pod")


## StatefulSet (Controller)

√â um objeto respons√°vel por gerenciar aplica√ß√µes que s√£o Stateful. Um Pod StatefulSet possui uma identidade √∫nica, uma identidade de rede est√°vel e um storage est√°vel ainda que haja reescalonamento do Pod para outro n√≥.

```
üí° Est√°vel, aqui, refere-se a persistente ainda que haja rescheduling do pod para outro n√≥
```

O StatefulSet garante a **ORDEM** e **UNICIDADE** dos Pods, mantendo suas identidades. Considera√ß√µes:

- StatefulSet permite dar start e stop em pods de acordo com uma sequ√™ncia espec√≠fica. Com Deployments voc√™ d√° start e stop nos Pods de forma rand√¥mica e √© OK isso ocorrer para servi√ßos stateless (onde cada r√©plica √© id√™ntica √† outra).
- √Äs vezes queremos iniciar Pods em uma sequ√™ncia numerada e estar apto a identific√°-los pelo n√∫mero (*e.g.* o Redis cria seu pr√≥prio cluster e precisa saber quem √© o leader por um nome previs√≠vel).
- Cada r√©plica deve est√° rodando e pronta antes do k8s dar start na pr√≥xima e, da mesma forma, quando um StatefulSet √© terminado, as r√©plicas ser√£o terminadas na ordem reversa, esperando para cada Pod finalizar antes de ir para o pr√≥ximo.
- StatefulSets s√£o usados para Pods colaborativos: eles necessitam ser inicializados em uma ordem espec√≠fica (*e.g.* replicas de BD).
- Para que possamos endere√ßar cada pod por um nome de DNS previs√≠vel (*e.g.* redis-1) voc√™ tamb√©m precisa criar um **Service com ClusterIp de tipo None (conhecido como *headless service*)**.
    - Com isso, voc√™ tem uma entrada de DNS (*e.g.* redis) que faz LoadBalancing entre todos os Pods. Al√©m disso, voc√™ tem um √∫nico nome DNS mas tamb√©m tem entradas de DNS individuais para cada n√∫mero do Pod (e.g. redis-0, redis-1, etc‚Ä¶)
    - Pods que precisarem entrar nesse cluster (de Redis, por exemplo) podem contactar redis-0 especificamente, mas aplica√ß√µes que precisem do LB Redis Service podem usar o DNS para se comunicar randomicamente com um pod.
- StatefulSets tamb√©m podem gerenciar armazenamento de disco para os Pods usando o **VolumeClaimTemplate** que automaticamente cria um **PersistentVolumeClaim**.

## DaemonSet

Garante que todos (ou alguns) nodes ativos est√£o rodando ao menos uma c√≥pia do Pod. Dinamicamente aloca pods em nodes no momento que s√£o criados e removidos.

Permite que seja executado um, e apenas um, agente em cada node. Muito √∫til para logs, por exemplo, onde queremos apenas 1 agente de logs por n√≥ (e n√£o por Pod sen√£o teremos replica√ß√£o de c√≥digo desnecessariamente).

## Job

Executa um Pod por um n√∫mero de vezes espec√≠fico. Ap√≥s isso, √© considerado conclu√≠do.

- **Completions** determina o n√∫mero de vezes que um Pod precisa executar com sucesso antes do Job ser considerado conclu√≠do. O valor default √© 1, ou seja, o pod ir√° executar uma √∫nica vez.
- **Parallelism** especifica quantos pods devem rodar por vez. O valor default √© 1, ou seja, apenas um Pod ir√° rodar por vez.

## Cronjobs

- **Spec.schedule** especifica quando o job ir√° rodar, usando o mesmo formato do cron no Unix.
- **Spec.jobTemplate** especifica o template para o Job que ser√° executado, e √© exatamente igual ao manifesto de um Job normal.

## Horizontal Pod Autoscalers

Permite que o Kubernetes ajuste o n√∫mero de r√©plicas para voc√™ de forma autom√°tica em resposta a uma demanda.

- Fica observando as m√©tricas do Deployment para ver se √© neces√°rio scale up ou down.
- Embora utiliza√ß√£o de CPU √© a m√©trica mais comum, voc√™ pode usar qualquer m√©trica dispon√≠vel para Kubernetes, incluindo *system metrics* como CPU e uso de mem√≥ria, e *service metrics* espec√≠ficos do app (que voc√™ define e exporta da sua aplica√ß√£o, como taxa de erro).

## PodPresets

Funcionalidade experimental no K8s que permite que voc√™ injete alguma informa√ß√£o nos Pods quando eles s√£o criados (e.g. voc√™ poderia criar um PodPreset que monta o volume em todos os Pods que d√£o match em um grupo de labels). √â considerado um tipo de objeto chamado *admission controller*. AC fazem watch em Pods que est√£o sendo criados e tomam alguma a√ß√£o quando esses pods d√£o match com o seletor.

## Custom Resource Definitions

CRD permite que voc√™ crie seu pr√≥prio tipo de objeto para aplica√ß√µes que precisam de um gerenciamento mais complicado. Alguns CRDs s√≥ existem para armazenar dados (*e.g.* Velero BackupStorageLocation) mas voc√™ pode ir al√©m e criar objetos que agem como Pod controllers, apenas como um Deployment ou StatefulSet.

## Ingress

Recurso que gerencia o acesso externo aos servi√ßos em um cluster. Ele fornece uma maneira de expor servi√ßos HTTP e HTTPS para o tr√°fego externo, geralmente para roteamento com base em regras espec√≠ficas.O Ingress recebe requests de clientes e envia para o Service que, ent√£o, envia para o Pod correto baseado no seletor. Voc√™ pode pensar no Ingress como um LB que fica na frente de um Servi√ßo.

Por exemplo, o Ingress abaixo encaminha o tr√°fego para um Servi√ßo de nome *demo-service* na porta 80.

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
    name: demo-ingress
spec:
    backend:
        serviceName: demo-service
        servicePort: 80
```

Enquanto que o Service roteia o tr√°fego interno do cluster, o Ingress Rule √© √∫til para roteamento de tr√°fego externo para dentro do cluster e para o microsservi√ßo apropriado.

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
    name: fanout-ingress
spec:
    rules:
    - http:
        paths:
        - path: /hello
          backend:
            serviceName: hello
            servicePort: 80
        - path: /goodbye
          backend:
            serviceName: goodbye
            servicePort: 80
```

LBs de alta disponibilidade podem ser caros. Ent√£o, fanout Ingress permite que voc√™ tenha 1 load balancer (e seus ingress associados) roteando o tr√°fego para um grande n√∫mero de servi√ßos. Voc√™ n√£o est√° limitado ao roteamento baseado nas URLs. Voc√™ pode tamb√©m usar HTTP Host header para que requisi√ß√µes para diferentes dom√≠nios sejam roteados para o Servi√ßo apropriado.

Ingress podem lidar com conex√µes seguras usando TLS (antes conhecido como SSL). Se voc√™ tem muitos servi√ßos diferentes e aplica√ß√µes no mesmo dom√≠nio, todas elas podem compartilhar o mesmo certificado TLS e um √∫nico Ingress pode gerenciar essas conex√µes (conhecido como TLS termination).

Voc√™ pode automaticamente requisitar e renovar os certificados TLS usando o popular LetsEncrypt. Basta usar o cert-manager (http://docs.cert-manager.io/en/latest/). Se voc√™ execut√°-lo no seu cluster ele automaticamente vai detectar TLS Ingresses que n√£o tenham certificados e requisitar um do provedor especificado (*e.g.* LetsEncrypt). *Cert-manager √© mais moderno e o sucessor do kube-lego.*

A forma como as conex√µes TLS s√£o tratadas depende do **Ingress Controller**. O ingress controller √© respons√°vel por gerenciar os recursos no seu cluster. Dependendo de onde voc√™ est√° rodando o cluster, o controller pode variar. Geralmente, customizar o comportamento do seu Ingress √© feito ao adicionar annotations espec√≠ficos que s√£o reconhecidos pelo controller. GKE tem a op√ß√£o do Compute LB e a AWS tem um produto similar chamado de Application Load Balancer. Esses servi√ßos prov√™em um IP p√∫blico onde o ingress vai fazer listening para requests.

Voc√™ tamb√©m pode instalar e rodar seu pr√≥prio Ingres Controller dentro do cluster, ou mesmo executar m√∫ltiplos controllers se quiser. Algumas op√ß√µes s√£o: nginx-ingress, contour e traefik. A maioria dos servi√ßos de k8s gerenci√°veis prov√™m alguma forma de integra√ß√£o com um Cloud Load Balancer. Por exemplo, ao criar um servi√ßo LB no GKE, ou Ingress, um Cloud LB √© automaticamente criado e conectado ao seu servi√ßo.
